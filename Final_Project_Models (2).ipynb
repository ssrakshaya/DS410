{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654e943d-9179-4e1c-ae94-512dfb4f02b4",
   "metadata": {},
   "source": [
    "## DS 410 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ba68a7-e26d-48c7-bbb2-f2079a4cf147",
   "metadata": {},
   "source": [
    "Importing libraries, Creating Spark Session, and Reading in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8397d72-41f7-44d1-bb7d-0d79f8bb934c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import lower\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType, IntegerType, FloatType\n",
    "from pyspark.sql.functions import col, column\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql import Row\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sparknlp\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt', quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36af5aca-ccf0-44b2-96bb-4a3c81a5a165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/06 09:41:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "ss=SparkSession.builder.master(\"local\").appName(\"Final_Project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eb927ae-c36a-4a43-800f-c7efc31a7423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sparknlp\n",
    "\n",
    "# # Attach Spark NLP to the existing Spark session\n",
    "# sparknlp.start()\n",
    "\n",
    "# print(\"Spark NLP version:\", sparknlp.version())\n",
    "# print(\"Spark version:\", ss.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "586a2bdd-dab3-49a1-92f1-28a11019c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.sparkContext.setCheckpointDir(\"~/scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edfc3e79-9363-4105-b577-01d72ce11111",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"Sentiment\", IntegerType(), nullable = False), \\\n",
    "                     StructField(\"Title\", StringType(), nullable = False), \\\n",
    "                     StructField(\"Text\", StringType(), nullable = False)\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1962ae53-8624-4d5c-a2b4-e6943777d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews1 = ss.read.csv(\"Amazon_reviews_sample.csv\", schema = schema, header = True, inferSchema = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbe63e2d-ff46-4f97-907e-c4016bbcfdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews1.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "409ffa99-c0b7-4b0e-88d2-69298296cfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sentiment: integer (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9c26b54-ee74-4fa3-8852-85246d35cf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+\n",
      "|Sentiment|               Title|                Text|\n",
      "+---------+--------------------+--------------------+\n",
      "|        1|Sorry I wasted my...|Neil Gaiman wrote...|\n",
      "|        1|Loved the prose, ...|Rabbit was not a ...|\n",
      "|        2|         FASCINATING|Am a Jack Higgins...|\n",
      "|        1|Little Annie Fann...|This was very, ve...|\n",
      "|        2|     pressing matter|I have owned Rowe...|\n",
      "+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "reviews.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84205054-f8fc-4edb-aa8d-cbe9c5f746cf",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ff84f2-1354-486e-ae34-1ef2d7f0ad0c",
   "metadata": {},
   "source": [
    "## Distribution of Review Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad551a1-c48a-4a4a-8098-605e5b9aa1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews_label = reviews.withColumn(\"Labeled Sentiment\", when(reviews[\"Sentiment\"] == 2, \"Positive\").when(reviews[\"Sentiment\"] == 1, \"Negative\"))\n",
    "sentiment_counts = reviews_label.groupBy(\"Labeled Sentiment\").count()\n",
    "pandas_sentiment=sentiment_counts.toPandas()\n",
    "plt.bar(pandas_sentiment[\"Labeled Sentiment\"],pandas_sentiment[\"count\"])\n",
    "plt.title(\"Distribution of Review Sentiment\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Number of Reviews\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0061a3b-4959-4112-919d-2d18ea1105e5",
   "metadata": {},
   "source": [
    "Removing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c37ba6d3-4ea3-4c97-b704-069b2bd39416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "reviews_special_title = reviews_label.withColumn(\"Title\", regexp_replace(\"Title\", \"[^a-zA-Z0-9\\\\s]\", \"\"))\n",
    "reviews_only_text = reviews_special_title.withColumn(\"Text\", regexp_replace(\"Text\", \"[^a-zA-Z0-9\\\\s]\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ac0d42-e4be-4ad8-86b1-94cdcdc5a9b6",
   "metadata": {},
   "source": [
    "Making all words lowercase and splitting by space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf6f39f2-294b-4422-9a54-a696b077fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_split_title = reviews_label.withColumn(\"Title\", split(lower(reviews_label[\"Title\"]), \" \"))\n",
    "reviews_split_title_text = reviews_split_title.withColumn(\"Text\", split(lower(reviews_split_title[\"Text\"]), \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaabd1bd-17ee-422d-ba30-f5693af5a258",
   "metadata": {},
   "source": [
    "Removing stop words, making rdd of title of reviews and text of reviews for positive and negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17a0a3b9-5f16-41bc-b2a6-1683b4a43c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "remover = StopWordsRemover(inputCols=[\"Title\", \"Text\"], outputCols=[\"Title (No Stop Words)\", \"Text (No Stop Words)\"])\n",
    "reviews_no_stop_words = remover.transform(reviews_split_title_text)\n",
    "reviews_title_flat_pos = reviews_no_stop_words.filter(reviews_no_stop_words[\"Labeled Sentiment\"] == \"Positive\").select(\"Title (No Stop Words)\").rdd.flatMap(lambda x: x).flatMap(lambda x: x)\n",
    "reviews_text_flat_pos = reviews_no_stop_words.filter(reviews_no_stop_words[\"Labeled Sentiment\"] == \"Positive\").select(\"Text (No Stop Words)\").rdd.flatMap(lambda x: x).flatMap(lambda x: x)\n",
    "reviews_title_flat_neg = reviews_no_stop_words.filter(reviews_no_stop_words[\"Labeled Sentiment\"] == \"Negative\").select(\"Title (No Stop Words)\").rdd.flatMap(lambda x: x).flatMap(lambda x: x)\n",
    "reviews_text_flat_neg = reviews_no_stop_words.filter(reviews_no_stop_words[\"Labeled Sentiment\"] == \"Negative\").select(\"Text (No Stop Words)\").rdd.flatMap(lambda x: x).flatMap(lambda x: x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9aafe5-cdc5-4484-b9d6-a7bb30b41f25",
   "metadata": {},
   "source": [
    "Concatenate title and reviews rdd for positive and negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ceb37f6-c458-474c-a7d3-719a94db4424",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_pos = reviews_title_flat_pos.union(reviews_text_flat_pos)\n",
    "reviews_neg = reviews_title_flat_neg.union(reviews_text_flat_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1113cf0d-952f-46bf-8ffa-e5d8f2fa51bb",
   "metadata": {},
   "source": [
    "Map words to key-value pairs ex. (word, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a804a2a-2fd0-4576-98ad-8423271cad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_pos_key_val = reviews_pos.map(lambda x: (x, 1))\n",
    "reviews_neg_key_val = reviews_neg.map(lambda x: (x, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc79470-da26-4213-bc17-438c6e2baf27",
   "metadata": {},
   "source": [
    "Reduce key-value pairs by key (aggregate counts of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29f5cb2e-41a0-4b2a-b64b-9714c5246af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_pos_key_val_reduced = reviews_pos_key_val.reduceByKey(lambda x, y: x + y, 4)\n",
    "reviews_neg_key_val_reduced = reviews_neg_key_val.reduceByKey(lambda x, y: x + y, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40776cc-1b77-40d7-a59c-84ff5d196442",
   "metadata": {},
   "source": [
    "Sort aggregated counts of words in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6bd205a-6755-4c21-a7d0-eebc7a1dd71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "reviews_pos_key_val_sorted = reviews_pos_key_val_reduced.sortBy(lambda pair: pair[1], ascending=False)\n",
    "reviews_neg_key_val_sorted = reviews_neg_key_val_reduced.sortBy(lambda pair: pair[1], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2add36ec-7b9f-4e8d-b234-1b6f48ad4573",
   "metadata": {},
   "source": [
    "Get ten most frequent words for title of reviews and text of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "803ceed9-da57-4f35-b66d-5cabb7956610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "reviews_pos_key_val_sorted_top_ten = reviews_pos_key_val_sorted.take(10)\n",
    "reviews_neg_key_val_sorted_top_ten  = reviews_neg_key_val_sorted.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a41d4-2346-4615-9393-5584249937d6",
   "metadata": {},
   "source": [
    "## Bar graph of ten most frequent words in positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a05ea4b1-17a9-48a4-b00a-3a3002bc7153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([item[0] for item in reviews_pos_key_val_sorted_top_ten], [item[1] for item in reviews_pos_key_val_sorted_top_ten])\n",
    "plt.xlabel(\"Word\")\n",
    "plt.ylabel(\"Number of Occurences\")\n",
    "plt.title(\"Top Ten Most Frequently Used Words in Positive Reviews\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7d5956-cd1e-4a48-af01-1b011b3e53e4",
   "metadata": {},
   "source": [
    "## Bar graph of ten most frequent words in negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9efffb7-dea6-4862-88dc-5cf81eb17d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([item[0] for item in reviews_neg_key_val_sorted_top_ten], [item[1] for item in reviews_neg_key_val_sorted_top_ten])\n",
    "plt.xlabel(\"Word\")\n",
    "plt.ylabel(\"Number of Occurences\")\n",
    "plt.title(\"Top Ten Most Frequently Used Words in Negative Reviews\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f109894-032f-4c39-9464-1c9923427fff",
   "metadata": {},
   "source": [
    "# PreProcessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6be4149-2cb1-49e6-894f-a68ea857e92b",
   "metadata": {},
   "source": [
    "### Add Stemming\n",
    "Stemming reduces words to their root form (e.g., \"running\" -> \"run\", \"playing\" -> \"play\"\n",
    "\n",
    "Remove punctuation from each word and apply Porter Stemmer. (Porter Stemmer is a process of removing suffixes of words in five steps, reducing them to their root form, as degined above!)\n",
    "    \n",
    "Example:\n",
    "- Input:  ['sorry', 'wasted', 'time.', 'book!']\n",
    "- Output: ['sorri', 'wast', 'time', 'book']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa37053a-015e-468a-996a-26b4e9415355",
   "metadata": {},
   "source": [
    "Import Libraries Needed for Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3586fb9-1747-4841-bc49-8644c7b16f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Download NLTK data (run once)\n",
    "try:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    #print(\" NLTK data downloaded\")\n",
    "except:\n",
    "    print(\"NLTK data already available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "375f3755-9fe9-46fc-b313-e88d244e914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_stem_words(words):\n",
    "    #Remove punctuation from each word and apply Porter Stemmer\n",
    "    \n",
    "    if words is None:\n",
    "        return []\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    cleaned_stemmed = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Remove all non-alphabetic characters (punctuation, numbers, symbols)\n",
    "        clean_word = re.sub(r'[^a-zA-Z]', '', word)\n",
    "        \n",
    "        # Only process if something remains after cleaning\n",
    "        if clean_word:\n",
    "            # Apply stemming\n",
    "            stemmed = stemmer.stem(clean_word.lower())\n",
    "            cleaned_stemmed.append(stemmed)\n",
    "    \n",
    "    return cleaned_stemmed\n",
    "\n",
    "#Spark UDF\n",
    "clean_stem_udf = udf(clean_and_stem_words, ArrayType(StringType()))\n",
    "\n",
    "#print(\" Stemming function created (with punctuation removal)!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9094e4-3183-4e8a-b1bf-53524abcd837",
   "metadata": {},
   "source": [
    "### Apply stemming function to Reviews given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6041d104-02d9-40b7-8ef1-bea0e8a0c0c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Columns are named \"Title (No Stop Words)\" and \"Text (No Stop Words)\"\n",
    "# with spaces and parentheses, use backticks to reference columns with spaces\n",
    "# we apply the clean stemming function to these cells \n",
    "\n",
    "# Apply to both columns\n",
    "reviews_stemmed = reviews_no_stop_words.withColumn(\n",
    "    \"Title_Stemmed\",\n",
    "    clean_stem_udf(col(\"`Title (No Stop Words)`\"))\n",
    ").withColumn(\n",
    "    \"Text_Stemmed\",\n",
    "    clean_stem_udf(col(\"`Text (No Stop Words)`\"))\n",
    ")\n",
    "\n",
    "#print(f\"Stemming Total records: {reviews_stemmed.count():,}\")\n",
    "\n",
    "# Show example of the transformation\n",
    "#print(\"\\n\" + \"=\"*70)\n",
    "#print(\"EXAMPLE: Before vs After Cleaning + Stemming\")\n",
    "#print(\"=\"*70)\n",
    "\n",
    "\n",
    "# sample = reviews_stemmed.select(\n",
    "#     \"`Title (No Stop Words)`\", \n",
    "#     \"Title_Stemmed\",\n",
    "#     \"`Text (No Stop Words)`\", \n",
    "#     \"Text_Stemmed\"\n",
    "# ).first()\n",
    "\n",
    "# print(\"\\n TITLE:\")\n",
    "# print(f\"  Before: {sample['Title (No Stop Words)'][:5]}\")\n",
    "# print(f\"  After:  {sample['Title_Stemmed'][:5]}\")\n",
    "\n",
    "# print(\"\\n TEXT:\")\n",
    "# print(f\"  Before: {sample['Text (No Stop Words)'][:5]}\")\n",
    "# print(f\"  After:  {sample['Text_Stemmed'][:5]}\")\n",
    "\n",
    "# print(\"\\n Punctuation removed and words stemmed!\")\n",
    "# print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de22e25c-5b7b-4c74-b937-279c9623a1ec",
   "metadata": {},
   "source": [
    "### Preparing Data for Hugging Face\n",
    "\n",
    "Formatting to be used by transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15905206-5e15-4395-aecd-9a11be9b7173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws, array_join, when\n",
    "\n",
    "# Combine stemmed title + text into one column for transformers that can be used for model output\n",
    "# Create binary labels (0=Negative, 1=Positive) used by Hugging Face. \n",
    "\n",
    "reviews_for_transformers = reviews_stemmed.withColumn(\n",
    "    \"text\",  # Column name expected by Hugging Face\n",
    "    concat_ws(\" \", \n",
    "              array_join(col(\"Title_Stemmed\"), \" \"),\n",
    "              array_join(col(\"Text_Stemmed\"), \" \"))\n",
    ").withColumn(\n",
    "    \"label\",  # Binary label: 0=Negative, 1=Positive\n",
    "    when(col(\"Sentiment\") == 2, 1).otherwise(0)\n",
    ").select(\"text\", \"label\", \"Sentiment\", \"Labeled Sentiment\")\n",
    "\n",
    "#print(\"Data prepared for Hugging Face transformers!\")\n",
    "#print(\"\\n\" + \"=\"*70)\n",
    "#print(\"Sample of Transformer-Ready Data:\")\n",
    "#print(\"=\"*70)\n",
    "#reviews_for_transformers.show(3, truncate=70, vertical=False)\n",
    "\n",
    "#print(\"\\nData format:\")\n",
    "#print(\"   text:   Combined, cleaned, stemmed review text\")\n",
    "#print(\"   label:  Binary (0=Negative, 1=Positive)\")\n",
    "#print(\"   Ready for BERT, RoBERTa, DistilBERT, etc.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaa64be-cb87-41bf-87e3-a90f8c8d5cb6",
   "metadata": {},
   "source": [
    "## Creating Test Train Split\n",
    "Split data: 60% training, 20% validation, 20% testing\n",
    "- Validation is used for hyperparameter tuning\n",
    "- Test is used for final model evaluation\n",
    "- Use seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "daa1aac9-7429-4e0d-99c8-21c00e8a9866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Complete:\n",
      "  Training:   240,349 (60.1%)\n",
      "  Validation: 79,658 (19.9%)\n",
      "  Test:       79,967 (20.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Split data: 60% training, 20% testing, 20% validation\n",
    "# Use seed for reproducibility\n",
    "train_data, valid_data, test_data = reviews_for_transformers.randomSplit([0.6, 0.2, 0.2], seed=42)\n",
    "\n",
    "# Cache all three sets for faster access during modeling\n",
    "train_data.cache()\n",
    "valid_data.cache()\n",
    "test_data.cache()\n",
    "\n",
    "\n",
    "# Count records (forces computation and caching)\n",
    "train_count = train_data.count()\n",
    "valid_count = valid_data.count()\n",
    "test_count = test_data.count()\n",
    "total_count = train_count + valid_count + test_count\n",
    "\n",
    "\n",
    "# print(\"Data split complete!\")\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"Dataset Statistics:\")\n",
    "# print(\"=\"*70)\n",
    "# print(f\"  Training set: {train_count:,} records ({100*train_count/total_count:.1f}%)\")\n",
    "# print(f\"  Test set:     {test_count:,} records ({100*test_count/total_count:.1f}%)\")\n",
    "# print(f\"  Total:        {total_count:,} records\")\n",
    "\n",
    "# # Check label distribution in both sets\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"Label Distribution:\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# print(\"\\n Training Set:\")\n",
    "# train_label_dist = train_data.groupBy(\"label\", \"Labeled Sentiment\").count().orderBy(\"label\")\n",
    "# train_label_dist.show()\n",
    "\n",
    "# print(\" Test Set:\")\n",
    "# test_label_dist = test_data.groupBy(\"label\", \"Labeled Sentiment\").count().orderBy(\"label\")\n",
    "# test_label_dist.show()\n",
    "\n",
    "# # Check if balanced\n",
    "# train_labels = train_data.groupBy(\"label\").count().collect()\n",
    "# balance_ratio = min(train_labels[0]['count'], train_labels[1]['count']) / max(train_labels[0]['count'], train_labels[1]['count'])\n",
    "# print(f\"Class balance: {balance_ratio:.2%} ({'Balanced' if balance_ratio > 0.9 else 'Slightly imbalanced'})\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Split Complete:\")\n",
    "print(f\"  Training:   {train_count:,} ({train_count/(train_count+valid_count+test_count)*100:.1f}%)\")\n",
    "print(f\"  Validation: {valid_count:,} ({valid_count/(train_count+valid_count+test_count)*100:.1f}%)\")\n",
    "print(f\"  Test:       {test_count:,} ({test_count/(train_count+valid_count+test_count)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea91788-7c82-436c-b88b-bc1cfead5188",
   "metadata": {},
   "source": [
    "## Saving Preprocessed Data\n",
    "\n",
    "This step saves the cleaned and split datasets (train, validation, test) to disk in Parquet format so they can be reloaded later without rerunning preprocessing. Each dataset is written to its own folder for efficient access during model training.\n",
    "\n",
    "Key points:\n",
    "\n",
    "- Stores final data in /preprocessed_data_sample directory\n",
    "- Uses mode(\"overwrite\") to replace old files\n",
    "- Parquet format = fast, compressed, and Spark-friendly\n",
    "- Makes results reproducible and ready for transformer models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d0fe22c-e4d4-4811-920a-a1d04aa32834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Validation saved\n",
      " Test saved\n",
      "All data saved and memory freed!\n",
      "\n",
      "Modeling team can load with:\n",
      "  spark.read.parquet(\"preprocessed_data_sample/train_transformer_ready\")\n",
      "  spark.read.parquet(\"preprocessed_data_sample/valid_transformer_ready\")\n",
      "  spark.read.parquet(\"preprocessed_data_sample/test_transformer_ready\")\n"
     ]
    }
   ],
   "source": [
    "# Set output path \n",
    "OUTPUT_PATH = \"preprocessed_data_sample\"\n",
    "\n",
    "# print(\"=\"*70)\n",
    "# print(\"Saving Preprocessed Data...\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# # Save training data\n",
    "# print(f\"\\nSaving training data...\")\n",
    "# train_data.write.mode(\"overwrite\").parquet(f\"{OUTPUT_PATH}/train_transformer_ready\")\n",
    "# print(f\"   Saved to: {OUTPUT_PATH}/train_transformer_ready/\")\n",
    "\n",
    "# # Save validation data (NEW!)\n",
    "# print(f\"\\nSaving validation data...\")\n",
    "# valid_data.write.mode(\"overwrite\").parquet(f\"{OUTPUT_PATH}/valid_transformer_ready\")\n",
    "# print(f\"   Saved to: {OUTPUT_PATH}/valid_transformer_ready/\")\n",
    "\n",
    "# # Save test data\n",
    "# print(f\"\\nSaving test data...\")\n",
    "# test_data.write.mode(\"overwrite\").parquet(f\"{OUTPUT_PATH}/test_transformer_ready\")\n",
    "# print(f\"   Saved to: {OUTPUT_PATH}/test_transformer_ready/\")\n",
    "\n",
    "# # Save full stemmed dataset (includes all columns for reference)\n",
    "# print(f\"\\nSaving full stemmed dataset...\")\n",
    "# reviews_stemmed.write.mode(\"overwrite\").parquet(f\"{OUTPUT_PATH}/reviews_stemmed\")\n",
    "# print(f\"   Saved to: {OUTPUT_PATH}/reviews_stemmed/\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"All data saved successfully!\")\n",
    "# print(\"=\"*70)\n",
    "# print(f\"\\nModeling team can load with:\")\n",
    "# print(f'  train_df = spark.read.parquet(\"{OUTPUT_PATH}/train_transformer_ready\")')\n",
    "# print(f'  valid_df = spark.read.parquet(\"{OUTPUT_PATH}/valid_transformer_ready\")')\n",
    "# print(f'  test_df = spark.read.parquet(\"{OUTPUT_PATH}/test_transformer_ready\")')\n",
    "\n",
    "\n",
    "\n",
    "print(\"Saving data: \")\n",
    "\n",
    "train_data.write.mode(\"overwrite\").parquet(f\"{OUTPUT_PATH}/train_transformer_ready\")\n",
    "print(f\" Training saved\")\n",
    "\n",
    "valid_data.write.mode(\"overwrite\").parquet(f\"{OUTPUT_PATH}/valid_transformer_ready\")\n",
    "print(f\" Validation saved\")\n",
    "\n",
    "test_data.write.mode(\"overwrite\").parquet(f\"{OUTPUT_PATH}/test_transformer_ready\")\n",
    "print(f\" Test saved\")\n",
    "\n",
    "# Free up memory\n",
    "train_data.unpersist()\n",
    "valid_data.unpersist()\n",
    "test_data.unpersist()\n",
    "\n",
    "print(\"All data saved and memory freed!\")\n",
    "print(f\"\\nModeling team can load with:\")\n",
    "print(f'  spark.read.parquet(\"{OUTPUT_PATH}/train_transformer_ready\")')\n",
    "print(f'  spark.read.parquet(\"{OUTPUT_PATH}/valid_transformer_ready\")')\n",
    "print(f'  spark.read.parquet(\"{OUTPUT_PATH}/test_transformer_ready\")')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8188f6fb-8efc-4250-bbc2-08d110127ead",
   "metadata": {},
   "source": [
    "## Spark imports for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "868cbb40-5de3-4643-b14d-82165c0798f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f2549-674a-4f7a-ba79-30fed59fe365",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "571d67fd-6a94-483d-860a-d8e810d7246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = ss.read.parquet(\"preprocessed_data_sample/train_transformer_ready\")\n",
    "valid_df = ss.read.parquet(\"preprocessed_data_sample/valid_transformer_ready\")\n",
    "test_df  = ss.read.parquet(\"preprocessed_data_sample/test_transformer_ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3e6fb6-da93-4e55-8bc3-646b3e556421",
   "metadata": {},
   "source": [
    "## Tokenizing & tf/idf and casting to doubles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18bb001c-ffca-4c01-9c65-53eb944059d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast label in ALL splits (SVM expects double)\n",
    "train_df = train_df.withColumn(\"label\", col(\"label\").cast(\"double\"))\n",
    "valid_df = valid_df.withColumn(\"label\", col(\"label\").cast(\"double\"))\n",
    "test_df  = test_df.withColumn(\"label\",  col(\"label\").cast(\"double\"))\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "tf        = HashingTF(inputCol=\"tokens\", outputCol=\"rawFeatures\", numFeatures=100_000)\n",
    "idf       = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a81c769-656b-4e71-85ab-1df49d0183a7",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6325b943-b801-4d17-916e-2131ed4e09f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/04 09:49:34 WARN DAGScheduler: Broadcasting large task binary with size 1630.3 KiB\n",
      "25/11/04 09:49:45 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/11/04 09:49:45 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:49:57 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:49:57 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:49:58 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:49:58 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:49:58 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:49:58 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:49:58 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:49:58 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:49:59 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:49:59 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:49:59 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:49:59 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:49:59 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:00 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:00 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:00 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:00 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:00 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:00 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:01 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:01 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:01 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:01 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:01 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:01 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:01 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:02 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:02 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:02 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:02 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:02 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:02 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:03 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:03 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:03 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:03 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:03 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:03 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:04 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:04 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:04 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:04 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:04 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:04 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:05 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:05 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:05 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:05 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:05 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:05 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:05 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:06 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:06 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:06 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:06 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:06 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:07 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:07 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:07 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:07 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:07 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:07 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:07 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:07 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:08 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:08 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:08 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:08 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:08 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:09 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:09 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:09 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:09 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:09 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:09 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:09 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:10 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:10 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:10 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:10 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:10 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:10 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:10 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:11 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:11 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:11 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:11 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:11 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:11 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:11 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:12 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:12 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:12 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:12 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:12 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:12 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:13 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:13 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:13 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:13 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:13 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:13 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:13 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:13 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:14 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:14 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:14 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:14 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:14 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:14 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:15 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:15 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:15 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:15 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:15 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:15 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:15 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:15 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:16 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:16 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:16 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:16 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:16 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:16 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:17 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:17 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:17 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:17 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:17 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:17 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:17 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:18 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:18 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:18 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:18 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:18 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:18 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:18 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:18 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:19 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:19 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:19 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:19 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:19 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:19 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:19 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:20 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:20 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:20 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:20 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:20 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:20 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:20 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:21 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:21 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:21 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:21 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:21 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:21 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:21 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:21 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:22 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:22 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:22 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:22 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:22 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:22 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:22 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:23 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:23 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:23 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:23 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:23 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:23 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:23 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:23 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:24 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:24 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:24 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:24 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:24 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:24 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:24 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:25 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:25 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:25 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:25 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:25 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:25 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:25 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:25 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:26 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:26 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:26 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:26 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:26 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:26 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:26 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:27 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:27 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:27 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n",
      "25/11/04 09:50:27 WARN DAGScheduler: Broadcasting large task binary with size 1630.9 KiB\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(featuresCol=\"features\", labelCol=\"label\", maxIter=100, regParam=0.1)\n",
    "pipeline = Pipeline(stages=[tokenizer, tf, idf, svm])\n",
    "# Ignore warnings it runs fine\n",
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a259de18-7573-41c5-bcf3-959bad9ca227",
   "metadata": {},
   "source": [
    "## Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3722c71a-d751-4ba1-bd6d-824893976af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/04 09:50:43 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "25/11/04 09:50:47 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "25/11/04 09:50:50 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation  F1: 0.8497657830383619 | Accuracy: 0.8497702678952522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/04 09:50:53 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "[Stage 247:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test         F1: 0.8476471756004236 | Accuracy: 0.8476746657996423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator_f1  = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "valid_pred = model.transform(valid_df)\n",
    "test_pred  = model.transform(test_df)\n",
    "\n",
    "print(\"Validation  F1:\", evaluator_f1.evaluate(valid_pred), \"| Accuracy:\", evaluator_acc.evaluate(valid_pred))\n",
    "print(\"Test         F1:\", evaluator_f1.evaluate(test_pred),  \"| Accuracy:\", evaluator_acc.evaluate(test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e21ef48-e508-4a9a-97e4-1bcc55670720",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20793a9b-9341-49c4-9c17-5a734a79a5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_df = ss.read.parquet(\"preprocessed_data_sample/train_transformer_ready\")\n",
    "valid_df = ss.read.parquet(\"preprocessed_data_sample/valid_transformer_ready\")\n",
    "test_df  = ss.read.parquet(\"preprocessed_data_sample/test_transformer_ready\")\n",
    "\n",
    "for name in (\"train_df\",\"valid_df\",\"test_df\"):\n",
    "    locals()[name] = locals()[name].withColumn(\"label\", col(\"label\").cast(\"double\"))\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "tf  = HashingTF(inputCol=\"tokens\", outputCol=\"rawFeatures\", numFeatures=50_000)  #  from 200k\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "featurizer = Pipeline(stages=[tokenizer, tf, idf]).fit(train_df)\n",
    "train_f = featurizer.transform(train_df).select(\"features\", \"label\").repartition(1).cache()\n",
    "valid_f = featurizer.transform(valid_df).select(\"features\", \"label\").repartition(1).cache()\n",
    "test_f  = featurizer.transform(test_df ).select(\"features\", \"label\").repartition(1).cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1800b127-9b6d-4bb5-a2ea-35d4e46c6fee",
   "metadata": {},
   "source": [
    "## XGBOOST Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02cfb978-3fd8-4269-a911-92713617eed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 10:02:27,349 INFO XGBoost-PySpark: _fit Running xgboost-2.1.4 on 1 workers with\n",
      "\tbooster params: {'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'device': 'cpu', 'eval_metric': 'aucpr', 'max_depth': 6, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'scale_pos_weight': 0.9997254370127547, 'subsample': 0.8, 'tree_method': 'hist', 'num_round': 150, 'eta': 0.1, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2025-11-04 10:02:31,902 INFO XGBoost-PySpark: _train_booster Training on CPUs 1]\n",
      "[10:02:33] Task 0 got rank 0\n",
      "25/11/04 10:03:08 ERROR Executor: Exception in task 0.0 in stage 273.0 (TID 289)\n",
      "org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:123)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)\n",
      "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
      "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
      "\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.hasNext(SerDeUtil.scala:88)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeNextElementToStream(PythonRDD.scala:333)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$2.writeNextInputToStream(PythonRunner.scala:906)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.writeAdditionalInputToPythonWorker(PythonRunner.scala:844)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:767)\n",
      "\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:258)\n",
      "\tat java.base/java.io.BufferedInputStream.implRead(BufferedInputStream.java:292)\n",
      "\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:279)\n",
      "\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:381)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:933)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.mutable.Growable.addAll(Growable.scala:61)\n",
      "\tat scala.collection.mutable.Growable.addAll$(Growable.scala:57)\n",
      "\tat scala.collection.mutable.ArrayBuilder.addAll(ArrayBuilder.scala:75)\n",
      "\tat scala.collection.IterableOnceOps.toArray(IterableOnce.scala:1505)\n",
      "\tat scala.collection.IterableOnceOps.toArray$(IterableOnce.scala:1498)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1057)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: java.net.SocketException: Connection reset\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:401)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:434)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:756)\n",
      "\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:258)\n",
      "\tat java.base/java.io.BufferedInputStream.implRead(BufferedInputStream.java:292)\n",
      "\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:279)\n",
      "\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:381)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:104)\n",
      "\t... 37 more\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/home/cas7689/.local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 200, in manager\n",
      "  File \"/storage/home/cas7689/.local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 81, in worker\n",
      "  File \"/storage/home/cas7689/.local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 2068, in main\n",
      "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
      "  File \"/storage/home/cas7689/.local/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 597, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "25/11/04 10:03:08 WARN TaskSetManager: Lost task 0.0 in stage 273.0 (TID 289) (p-sc-2348.2e.hpc.psu.edu executor driver): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:123)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)\n",
      "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
      "\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n",
      "\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.hasNext(SerDeUtil.scala:88)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeNextElementToStream(PythonRDD.scala:333)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$2.writeNextInputToStream(PythonRunner.scala:906)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.writeAdditionalInputToPythonWorker(PythonRunner.scala:844)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:767)\n",
      "\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:258)\n",
      "\tat java.base/java.io.BufferedInputStream.implRead(BufferedInputStream.java:292)\n",
      "\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:279)\n",
      "\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:381)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:933)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.mutable.Growable.addAll(Growable.scala:61)\n",
      "\tat scala.collection.mutable.Growable.addAll$(Growable.scala:57)\n",
      "\tat scala.collection.mutable.ArrayBuilder.addAll(ArrayBuilder.scala:75)\n",
      "\tat scala.collection.IterableOnceOps.toArray(IterableOnce.scala:1505)\n",
      "\tat scala.collection.IterableOnceOps.toArray$(IterableOnce.scala:1498)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1057)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "Caused by: java.net.SocketException: Connection reset\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:401)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:434)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:756)\n",
      "\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:258)\n",
      "\tat java.base/java.io.BufferedInputStream.implRead(BufferedInputStream.java:292)\n",
      "\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:279)\n",
      "\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:381)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:104)\n",
      "\t... 37 more\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Could not recover from a failed barrier ResultStage. Most recent failure reason: Stage failed because barrier task ResultTask(273, 0) finished unsuccessfully.\norg.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:123)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.hasNext(SerDeUtil.scala:88)\n\tat org.apache.spark.api.python.PythonRDD$.writeNextElementToStream(PythonRDD.scala:333)\n\tat org.apache.spark.api.python.PythonRunner$$anon$2.writeNextInputToStream(PythonRunner.scala:906)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.writeAdditionalInputToPythonWorker(PythonRunner.scala:844)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:767)\n\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:258)\n\tat java.base/java.io.BufferedInputStream.implRead(BufferedInputStream.java:292)\n\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:279)\n\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:381)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:933)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.mutable.Growable.addAll(Growable.scala:61)\n\tat scala.collection.mutable.Growable.addAll$(Growable.scala:57)\n\tat scala.collection.mutable.ArrayBuilder.addAll(ArrayBuilder.scala:75)\n\tat scala.collection.IterableOnceOps.toArray(IterableOnce.scala:1505)\n\tat scala.collection.IterableOnceOps.toArray$(IterableOnce.scala:1498)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1057)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n\tat java.base/java.lang.Thread.run(Thread.java:1623)\nCaused by: java.net.SocketException: Connection reset\n\tat java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:401)\n\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:434)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:756)\n\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:258)\n\tat java.base/java.io.BufferedInputStream.implRead(BufferedInputStream.java:292)\n\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:279)\n\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:381)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:104)\n\t... 37 more\n\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n\tat scala.collection.immutable.List.foreach(List.scala:334)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:2283)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3201)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:578)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3479588/3248924911.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mscale_pos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale_pos_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mxgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             raise TypeError(\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xgboost/spark/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0mdmatrix_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         )\n\u001b[0;32m-> 1130\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbooster\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0mget_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LOG_TAG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished xgboost training!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/xgboost/spark/core.py\u001b[0m in \u001b[0;36m_run_job\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1113\u001b[0m             )\n\u001b[1;32m   1114\u001b[0m             \u001b[0mrdd_with_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_stage_level_scheduling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd_with_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pyspark/core/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1698\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    328\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Could not recover from a failed barrier ResultStage. Most recent failure reason: Stage failed because barrier task ResultTask(273, 0) finished unsuccessfully.\norg.apache.spark.SparkException: Python worker exited unexpectedly (crashed). Consider setting 'spark.sql.execution.pyspark.udf.faulthandler.enabled' or'spark.python.worker.faulthandler.enabled' configuration to 'true' for the better Python traceback.\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:621)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$1.applyOrElse(PythonRunner.scala:599)\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:123)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.hasNext(SerDeUtil.scala:88)\n\tat org.apache.spark.api.python.PythonRDD$.writeNextElementToStream(PythonRDD.scala:333)\n\tat org.apache.spark.api.python.PythonRunner$$anon$2.writeNextInputToStream(PythonRunner.scala:906)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.writeAdditionalInputToPythonWorker(PythonRunner.scala:844)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:767)\n\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:258)\n\tat java.base/java.io.BufferedInputStream.implRead(BufferedInputStream.java:292)\n\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:279)\n\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:381)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:933)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:925)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.mutable.Growable.addAll(Growable.scala:61)\n\tat scala.collection.mutable.Growable.addAll$(Growable.scala:57)\n\tat scala.collection.mutable.ArrayBuilder.addAll(ArrayBuilder.scala:75)\n\tat scala.collection.IterableOnceOps.toArray(IterableOnce.scala:1505)\n\tat scala.collection.IterableOnceOps.toArray$(IterableOnce.scala:1498)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1057)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2524)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n\tat java.base/java.lang.Thread.run(Thread.java:1623)\nCaused by: java.net.SocketException: Connection reset\n\tat java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:401)\n\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:434)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:756)\n\tat java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:258)\n\tat java.base/java.io.BufferedInputStream.implRead(BufferedInputStream.java:292)\n\tat java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:279)\n\tat java.base/java.io.DataInputStream.readInt(DataInputStream.java:381)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:104)\n\t... 37 more\n\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:2935)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2935)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2927)\n\tat scala.collection.immutable.List.foreach(List.scala:334)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2927)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:2283)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3201)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2549)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1057)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:417)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1056)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:203)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:578)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:1623)\n"
     ]
    }
   ],
   "source": [
    "from xgboost.spark import SparkXGBClassifier\n",
    "\n",
    "pos = train_f.filter(col(\"label\") == 1.0).count()\n",
    "neg = train_f.filter(col(\"label\") == 0.0).count()\n",
    "scale_pos_weight = float(neg) / max(float(pos), 1.0)\n",
    "\n",
    "\n",
    "xgb = SparkXGBClassifier(\n",
    "    features_col=\"features\",\n",
    "    label_col=\"label\",\n",
    "    prediction_col=\"prediction\",\n",
    "    probability_col=\"probability\",\n",
    "    raw_prediction_col=\"rawPrediction\",\n",
    "    num_workers=1,              \n",
    "    tree_method=\"hist\",         \n",
    "    eval_metric=\"aucpr\",\n",
    "    num_round=150,\n",
    "    max_depth=6,\n",
    "    eta=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "xgb_model = xgb.fit(train_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e027c5c-4528-4bfb-824e-3a50de74eb34",
   "metadata": {},
   "source": [
    "## XGBoost accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85a758c5-f717-4f33-82cb-83e0b8161a2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3479588/387961001.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalid_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_pred\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0me_aucpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawPredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rawPrediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetricName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"areaUnderPR\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0me_auc\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mBinaryClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawPredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rawPrediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetricName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"areaUnderROC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "valid_pred = xgb_model.transform(valid_f).cache()\n",
    "test_pred  = xgb_model.transform(test_f).cache()\n",
    "\n",
    "e_aucpr = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\n",
    "e_auc   = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "e_f1    = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "e_acc   = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "print(\"Validation  AUC-PR:\", e_aucpr.evaluate(valid_pred),\n",
    "      \"| AUC-ROC:\", e_auc.evaluate(valid_pred),\n",
    "      \"| F1:\", e_f1.evaluate(valid_pred),\n",
    "      \"| Acc:\", e_acc.evaluate(valid_pred))\n",
    "\n",
    "print(\"Test         AUC-PR:\", e_aucpr.evaluate(test_pred),\n",
    "      \"| AUC-ROC:\", e_auc.evaluate(test_pred),\n",
    "      \"| F1:\", e_f1.evaluate(test_pred),\n",
    "      \"| Acc:\", e_acc.evaluate(test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e9eec8-540f-4ef7-967c-d346fea044a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77368d88-dd46-401c-8f49-f0212f6b5576",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d40abaa8-2792-4ad1-a643-e80367dca3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "train_df = train_df.withColumn(\"label\", col(\"label\").cast(\"double\"))\n",
    "valid_df = valid_df.withColumn(\"label\", col(\"label\").cast(\"double\"))\n",
    "test_df  = test_df.withColumn(\"label\",  col(\"label\").cast(\"double\"))\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "tf        = HashingTF(inputCol=\"tokens\", outputCol=\"rawFeatures\", numFeatures=100_000)\n",
    "idf       = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff9493-20c4-42b2-bc0b-6712318762e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree model \n",
    "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\", maxDepth=10)\n",
    "\n",
    "# Full pipeline \n",
    "pipeline = Pipeline(stages=[tokenizer, tf, idf, dt])\n",
    "\n",
    "# Fit and evaluate \n",
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0dcd38-0db7-415d-be4a-186a3db1f38d",
   "metadata": {},
   "source": [
    "## Predictions and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83724c-7bc1-4220-abd2-d3e80d8407ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation and test data\n",
    "valid_pred = model.transform(valid_df)\n",
    "test_pred  = model.transform(test_df)\n",
    "\n",
    "# Evaluate accuracy \n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "valid_acc = evaluator.evaluate(valid_pred)\n",
    "test_acc  = evaluator.evaluate(test_pred)\n",
    "\n",
    "print(\"Validation Accuracy:\", valid_acc)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "# Show sample predictions\n",
    "test_pred.select(\"text\", \"label\", \"prediction\", \"probability\").show(5, truncate=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b8cdc7-c4b3-44a2-98b5-8b19102618ae",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "943650ca-eb03-40cd-902f-3717cccdbb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version: 6.2.0\n",
      "Spark version: 4.0.0\n"
     ]
    }
   ],
   "source": [
    "# stop current session \n",
    "ss.stop()\n",
    "\n",
    "# Rebuild Spark session WITH Spark NLP JARs attached\n",
    "from pyspark.sql import SparkSession\n",
    "import sparknlp\n",
    "\n",
    "ss = (SparkSession.builder\n",
    "    .appName(\"Final_Project\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.3.3\")\n",
    "    .getOrCreate())\n",
    "\n",
    "print(\"Spark NLP version:\", sparknlp.version())\n",
    "print(\"Spark version:\", ss.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "87aa03b2-3946-4aa9-8994-3bea9de257ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = ss.read.parquet(\"preprocessed_data_sample/train_transformer_ready\")\n",
    "valid_df = ss.read.parquet(\"preprocessed_data_sample/valid_transformer_ready\")\n",
    "test_df  = ss.read.parquet(\"preprocessed_data_sample/test_transformer_ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c048a6c5-c4d5-4418-b153-6b679bb6dd59",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'JavaPackage' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_331239/3736614657.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Step 1: NLP preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdocument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocumentAssembler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msetInputCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msetOutputCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"document\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pyspark/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_F\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sparknlp/base/document_assembler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mkeyword_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDocumentAssembler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"com.johnsnowlabs.nlp.DocumentAssembler\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setDefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"document\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcleanupMode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'disabled'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pyspark/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_F\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sparknlp/internal/annotator_transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, classname)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_class_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_java_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pyspark/ml/util.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mjava_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFuncT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'JavaPackage' object is not callable"
     ]
    }
   ],
   "source": [
    "# Install Spark NLP first if you haven't:\n",
    "# !pip install spark-nlp\n",
    "\n",
    "# import sparknlp\n",
    "from sparknlp.base import DocumentAssembler, EmbeddingsFinisher\n",
    "from sparknlp.annotator import BertEmbeddings, Tokenizer as NLPTokenizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "\n",
    "# BERT uses double\n",
    "\n",
    "train_df = train_df.withColumn(\"label\", col(\"label\").cast(\"double\"))\n",
    "valid_df = valid_df.withColumn(\"label\", col(\"label\").cast(\"double\"))\n",
    "test_df  = test_df.withColumn(\"label\",  col(\"label\").cast(\"double\"))\n",
    "\n",
    "# Step 1: NLP preprocessing \n",
    "document = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = NLPTokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "bert = BertEmbeddings.pretrained(\"bert_base_uncased\", \"en\") \\\n",
    "    .setInputCols([\"document\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "emb_finisher = EmbeddingsFinisher() \\\n",
    "    .setInputCols([\"embeddings\"]) \\\n",
    "    .setOutputCols([\"finished_embeddings\"]) \\\n",
    "    .setOutputAsVector(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae4d16a0-7fd2-4e45-9478-ed67c11352f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert BERT arrays to MLlib feature vectors \n",
    "def avg_embeddings(vectors):\n",
    "    if not vectors:\n",
    "        return None\n",
    "    length = len(vectors[0])\n",
    "    avg = [0.0] * length\n",
    "    for v in vectors:\n",
    "        for i in range(length):\n",
    "            avg[i] += float(v[i])\n",
    "    for i in range(length):\n",
    "        avg[i] /= len(vectors)\n",
    "    return Vectors.dense(avg)\n",
    "\n",
    "to_vector = udf(avg_embeddings, VectorUDT())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec55e86c-401f-4026-a4a8-2aa23745c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Logistic Regression Classifier \n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e798a5f4-f456-4dee-9ccf-44a2759b8c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Build pipeline \n",
    "nlp_pipeline = Pipeline(stages=[document, tokenizer, bert, emb_finisher])\n",
    "nlp_model = nlp_pipeline.fit(train_df)\n",
    "\n",
    "# Transform to get embeddings\n",
    "train_emb = nlp_model.transform(train_df)\n",
    "valid_emb = nlp_model.transform(valid_df)\n",
    "test_emb  = nlp_model.transform(test_df)\n",
    "\n",
    "# Add a features column usable by MLlib\n",
    "train_emb = train_emb.withColumn(\"features\", to_vector(col(\"finished_embeddings\")))\n",
    "valid_emb = valid_emb.withColumn(\"features\", to_vector(col(\"finished_embeddings\")))\n",
    "test_emb  = test_emb.withColumn(\"features\", to_vector(col(\"finished_embeddings\")))\n",
    "\n",
    "# Drop null rows\n",
    "train_emb = train_emb.na.drop(subset=[\"features\", \"label\"])\n",
    "valid_emb = valid_emb.na.drop(subset=[\"features\", \"label\"])\n",
    "test_emb  = test_emb.na.drop(subset=[\"features\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcecf121-02f0-4803-9e2a-82e969d62caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train & evaluate\n",
    "lr_model = lr.fit(train_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775d6428-4a36-4f74-9c10-9a55019ee680",
   "metadata": {},
   "source": [
    "## Predictions and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce32913f-4c50-446e-97f8-64b7b0112ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_model.transform(test_emb)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "predictions.select(\"text\", \"label\", \"prediction\").show(5, truncate=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a133de-4f03-4478-87c8-9e753356c81d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985d5951-2440-4838-b751-f36e57952d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "train_df = train_df.withColumn(\"label\", col(\"label\").cast(\"double\"))\n",
    "valid_df = valid_df.withColumn(\"label\", col(\"label\").cast(\"double\"))\n",
    "test_df  = test_df.withColumn(\"label\",  col(\"label\").cast(\"double\"))\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "tf        = HashingTF(inputCol=\"tokens\", outputCol=\"rawFeatures\", numFeatures=100_000)\n",
    "idf       = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7456b67e-677b-4119-87df-b610232d059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree model \n",
    "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\", maxDepth=10)\n",
    "\n",
    "# Full pipeline \n",
    "pipeline = Pipeline(stages=[tokenizer, tf, idf, dt])\n",
    "\n",
    "# Fit and evaluate \n",
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f23ffd5-d4b1-4d1d-83e2-aed6c0b230d0",
   "metadata": {},
   "source": [
    "## Predictions and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7fe0ca-1d45-40e8-953e-957e73609554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation and test data\n",
    "valid_pred = model.transform(valid_df)\n",
    "test_pred  = model.transform(test_df)\n",
    "\n",
    "# Evaluate accuracy \n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "valid_acc = evaluator.evaluate(valid_pred)\n",
    "test_acc  = evaluator.evaluate(test_pred)\n",
    "\n",
    "print(\"Validation Accuracy:\", valid_acc)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "# Show sample predictions\n",
    "test_pred.select(\"text\", \"label\", \"prediction\", \"probability\").show(5, truncate=80"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds410_f25)",
   "language": "python",
   "name": "ds410_f25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
